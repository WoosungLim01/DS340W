{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading functions for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, column\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, IndexToString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset & data cleaning \n",
    "- 2.1 For data cleaning, we have changed the column name and changed the txt-type data into a csv-type file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the parsed JSON objects\n",
    "# Define the column names you want to extract\n",
    "columns = [\"reviewerID\", \"asin\", \"overall\"]\n",
    "\n",
    "# Initialize a list to hold the parsed JSON objects\n",
    "json_data = []\n",
    "\n",
    "# Read the JSON data from the file, line by line\n",
    "with open('reviews_Movies_and_TV_5.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Parse the JSON data and append the selected columns to the list\n",
    "        data = json.loads(line)\n",
    "        json_data.append({key: data[key] for key in columns})\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    csv_writer.writerow(columns)\n",
    "\n",
    "    # Write each row of data\n",
    "    for item in json_data:\n",
    "        csv_writer.writerow(item.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output.csv\", header = None, names=['reviewerID','productID', 'rating'])\n",
    "\n",
    "sampled_csv_data = df.sample(n=10000, random_state=1)\n",
    "\n",
    "# Save the sampled data to a new CSV file\n",
    "sampled_file_path = 'sample10000.csv'\n",
    "sampled_csv_data.to_csv(sampled_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Spark Session to use the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=SparkSession.builder.appName(\"Mini Project ALS-based Recommendation Systems\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(\"~/scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a rating_DF and rating_RDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_schema = StructType([ StructField(\"reviewerID\", StringType(), False ), \\\n",
    "                            StructField(\"productID\", StringType(), False), \\\n",
    "                            StructField(\"rating\", FloatType(), True ), \\\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_DF = ss.read.csv(\"sample1000.csv\", schema=rating_schema, header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- productID: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_DF = ratings_DF.select(\"reviewerID\",\"productID\",\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A3OL1AX1IODBYL', productID='B001NK74AU', rating=5.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings2_DF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(reviewerID='A3OL1AX1IODBYL', productID='B001NK74AU', rating=5.0),\n",
       " Row(reviewerID='A1A1PSZU6SLW9O', productID='B00005U0JX', rating=5.0),\n",
       " Row(reviewerID='A1G6NL5AQMZDAC', productID='B000BOH8Z0', rating=3.0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings2_RDD = ratings2_DF.rdd\n",
    "ratings2_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DataCleaning \n",
    "- labeling each reviewerID and ProductID a unique integer for furture mapreduce process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer= StringIndexer(inputCol=\"reviewerID\", outputCol=\"reviewerID_int\").fit(ratings2_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexerModel: uid=StringIndexer_a42dc29b7f99, handleInvalid=error"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = labelIndexer.transform(ratings2_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+--------------+\n",
      "|    reviewerID| productID|rating|reviewerID_int|\n",
      "+--------------+----------+------+--------------+\n",
      "|A3OL1AX1IODBYL|B001NK74AU|   5.0|          78.0|\n",
      "|A1A1PSZU6SLW9O|B00005U0JX|   5.0|        1445.0|\n",
      "|A1G6NL5AQMZDAC|B000BOH8Z0|   3.0|        1790.0|\n",
      "|A28IP5K9LFL7AV|B001J66JQS|   5.0|        3415.0|\n",
      "+--------------+----------+------+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer= StringIndexer(inputCol=\"productID\", outputCol=\"productID_int\").fit(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringIndexerModel: uid=StringIndexer_da4a12210a73, handleInvalid=error"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data_1 = labelIndexer.transform(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+--------------+-------------+\n",
      "|    reviewerID| productID|rating|reviewerID_int|productID_int|\n",
      "+--------------+----------+------+--------------+-------------+\n",
      "|A3OL1AX1IODBYL|B001NK74AU|   5.0|          78.0|       1399.0|\n",
      "|A1A1PSZU6SLW9O|B00005U0JX|   5.0|        1445.0|       3669.0|\n",
      "|A1G6NL5AQMZDAC|B000BOH8Z0|   3.0|        1790.0|       1244.0|\n",
      "|A28IP5K9LFL7AV|B001J66JQS|   5.0|        3415.0|       5719.0|\n",
      "+--------------+----------+------+--------------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data_1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transformed_data_1.select(\"reviewerID_int\",\"productID_int\",\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------+\n",
      "|reviewerID_int|productID_int|rating|\n",
      "+--------------+-------------+------+\n",
      "|          78.0|       1399.0|   5.0|\n",
      "|        1445.0|       3669.0|   5.0|\n",
      "|        1790.0|       1244.0|   3.0|\n",
      "|        3415.0|       5719.0|   5.0|\n",
      "+--------------+-------------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviewerID_int: double (nullable = false)\n",
      " |-- productID_int: double (nullable = false)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Splitting the data into training, validation, and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = data.rdd.randomSplit([3.0,1.0,1.0], 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_RDD = training_RDD.map(lambda x: (x[0], x[1]) )\n",
    "validation_input_RDD = validation_RDD.map(lambda x: (x[0], x[1]) ) \n",
    "testing_input_RDD = test_RDD.map(lambda x: (x[0], x[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the ALS model using a randomly assigned hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(training_RDD, 4, seed=17, iterations=30, lambda_=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prediction_RDD = model.predictAll(training_input_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=4904, product=336, rating=4.906144581712827),\n",
       " Rating(user=1084, product=4380, rating=4.910743992547013),\n",
       " Rating(user=3764, product=557, rating=4.911909577537192),\n",
       " Rating(user=7608, product=6930, rating=3.9053015442246846)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_prediction_RDD.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(reviewerID_int=78.0, productID_int=1399.0, rating=5.0),\n",
       " Row(reviewerID_int=21.0, productID_int=6941.0, rating=3.0),\n",
       " Row(reviewerID_int=1734.0, productID_int=450.0, rating=5.0)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target_output_RDD = training_RDD.map(lambda x: ( (x['reviewerID_int'], x['productID_int']), x['rating'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((78.0, 1399.0), 5.0), ((21.0, 6941.0), 3.0), ((1734.0, 450.0), 5.0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_target_output_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_prediction2_RDD = training_prediction_RDD.map(lambda x: (( x[0], x[1]), x[2] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4904, 336), 4.906144581712827),\n",
       " ((1084, 4380), 4.910743992547013),\n",
       " ((3764, 557), 4.911909577537192)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_prediction2_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluation_RDD = training_target_output_RDD.join(training_prediction2_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((78.0, 1399.0), (5.0, 4.914347743893639)),\n",
       " ((21.0, 6941.0), (3.0, 2.8990734581963244)),\n",
       " ((1096.0, 2093.0), (5.0, 4.910744263848937))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_evaluation_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = math.sqrt(training_evaluation_RDD.map(lambda z: (z[1][0] - z[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0939684405038181\n"
     ]
    }
   ],
   "source": [
    "print(training_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prediction_RDD = model.predictAll(validation_input_RDD).map(lambda x: ( (x[0], x[1]), x[2] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((140, 196), -2.308392890131816),\n",
       " ((4, 248), -2.52559004420781),\n",
       " ((4, 338), -2.7648625313100474)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_prediction_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_evaluation_RDD = validation_RDD.map(lambda y: ( ( y[0], y[1]), y[2] ) ).join(validation_prediction_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((638.0, 201.0), (2.0, 1.0823960309728573)),\n",
       " ((804.0, 104.0), (5.0, 0.3669750270530301)),\n",
       " ((560.0, 58.0), (5.0, -0.13069524042198544))]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_evaluation_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_error = math.sqrt(validation_evaluation_RDD.map(lambda z: (z[1][0] - z[1][1])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.887780122322847\n"
     ]
    }
   ],
   "source": [
    "print(validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best rank k is  10 , regularization =  0.1 , iterations =  15 . Validation Error = 4.209011096705229\n"
     ]
    }
   ],
   "source": [
    "## Initialize a Pandas DataFrame to store evaluation results of all combination of hyper-parameter settings\n",
    "hyperparams_eval_df = pd.DataFrame( columns = ['k', 'regularization', 'iterations', 'validation RMS', 'testing RMS'] )\n",
    "# initialize index to the hyperparam_eval_df to 0\n",
    "index =0 \n",
    "# initialize lowest_error\n",
    "lowest_validation_error = float('inf')\n",
    "# Set up the possible hyperparameter values to be evaluated\n",
    "iterations_list = [15, 30]\n",
    "regularization_list = [0.1, 0.2, 0.3]\n",
    "rank_list = [4, 7, 10, 13]\n",
    "for k in rank_list:\n",
    "    for regularization in regularization_list:\n",
    "        for iterations in iterations_list:\n",
    "            seed = 37\n",
    "            # Construct a recommendation model using a set of hyper-parameter values and training data\n",
    "            model = ALS.train(training_RDD, k, seed=17, iterations=30, lambda_=0.1)\n",
    "            # Evaluate the model using evalution data\n",
    "            # map the output into ( (userID, movieID), rating ) so that we can join with actual evaluation data\n",
    "            # using (userID, movieID) as keys.\n",
    "            validation_prediction_RDD= model.predictAll(validation_input_RDD).map(lambda x: ( (x[0], x[1]), x[2] )   )\n",
    "            validation_evaluation_RDD = validation_RDD.map(lambda y: ( (y[0], y[1]), y[2] ) ).join(validation_prediction_RDD)\n",
    "            # Calculate RMS error between the actual rating and predicted rating for (userID, movieID) pairs in validation dataset\n",
    "            validation_error = math.sqrt(validation_evaluation_RDD.map(lambda z: (z[1][0] - z[1][1])**2).mean())\n",
    "            # Save the error as a row in a pandas DataFrame\n",
    "            hyperparams_eval_df.loc[index] = [k, regularization, iterations, validation_error, float('inf')]\n",
    "            index = index + 1\n",
    "            # Check whether the current error is the lowest\n",
    "            if validation_error < lowest_validation_error:\n",
    "                best_k = k\n",
    "                best_regularization = regularization\n",
    "                best_iterations = iterations\n",
    "                best_index = index - 1\n",
    "                lowest_validation_error = validation_error\n",
    "print('The best rank k is ', best_k, ', regularization = ', best_regularization, ', iterations = ',\\\n",
    "      best_iterations, '. Validation Error =', lowest_validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the best hyperparameter combination using testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing Error for rank k = 10  regularization =  0.1 , iterations =  15  is :  4.366579976329201\n"
     ]
    }
   ],
   "source": [
    "seed = 37\n",
    "model = ALS.train(training_RDD, best_k, seed=seed, iterations=15, lambda_=0.1)\n",
    "testing_prediction_RDD=model.predictAll(testing_input_RDD).map(lambda x: ((x[0], x[1]), x[2]))\n",
    "testing_evaluation_RDD= test_RDD.map(lambda x: ((x[0], x[1]), x[2])).join(testing_prediction_RDD)\n",
    "testing_error = math.sqrt(testing_evaluation_RDD.map(lambda x: (x[1][0]-x[1][1])**2).mean())\n",
    "print('The Testing Error for rank k =', best_k, ' regularization = ', best_regularization, ', iterations = ', \\\n",
    "      best_iterations, ' is : ', testing_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(best_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Testing RMS in the DataFrame\n",
    "hyperparams_eval_df.loc[best_index]=[best_k, best_regularization, best_iterations, lowest_validation_error, testing_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema3= StructType([ StructField(\"k\", FloatType(), True), \\\n",
    "                      StructField(\"regularization\", FloatType(), True ), \\\n",
    "                      StructField(\"iterations\", FloatType(), True), \\\n",
    "                      StructField(\"Validation RMS\", FloatType(), True), \\\n",
    "                      StructField(\"Testing RMS\", FloatType(), True) \\\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperParams_RMS_DF = ss.createDataFrame(hyperparams_eval_df, schema3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/storage/home/wml5207/'MiniProject '/MiniProjectALSHyperParamTuning already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f9bf20f30241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/storage/home/wml5207/'MiniProject '/MiniProjectALSHyperParamTuning\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mHyperParams_RMS_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0mlineSep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineSep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m         )\n\u001b[0;32m-> 1799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m     def orc(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/storage/home/wml5207/'MiniProject '/MiniProjectALSHyperParamTuning already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "output_path = \"/storage/home/wml5207/'MiniProject '/MiniProjectALSHyperParamTuning\"\n",
    "HyperParams_RMS_DF.write.option(\"header\", True).csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
